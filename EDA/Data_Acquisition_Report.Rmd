---
title: "Data Acquisition"
author: "Erica Wong, Cindy Kang, and Abby Vogel"
date: "4/25/2017"
output: pdf_document
---

Loading the Data:
```{r}
data <- read.csv('../full_data_v4.csv', header = T)
data$X <- NULL
data$X.1 <- NULL
```

Number of Rows:
```{r}
(nrow(data))
```

First 5 Rows of Data:
```{r}
head(data, 5)
```

Summary:
```{r}
summary(data)
```

Plot:
```{r}
library(ggplot2)
er <- table(data$bmi, data$enjoy_pe)
mosaicplot(er, las=1, xlab="BMI", ylab="Enjoy PE", main="BMI and PE Enjoyment")
```

What We Did:

In order to get the data to this point, we first looked at the code book of each of the data sets that we were interested in using. Then using the plyr and dplyr packages, we were able to join all of the different SAS files that we were interested in using based upon the given ID. Because the column names are coded by something that is impossible to understand without having the code book open, we started off by renaming our columns to something that can be understood by a person who is reading our code. Additionally, since all the variables are coded by numbers, we replaced the numbers with informative factors that allow us to know what the data is telling us about the subjects without needing to look up what each number for each column means.

Finally, we looked at our data and realized that there were some missing values, We noticed that in our data, some of the rows had weights of 0 and contained many NAs in the row. We removed these from our data because we believed this to be unit non-response, so there was nothing that we could do with those people and it would not make sense to try to fill in their response. Additionally, one of columns that was giving us a lot of NAs was freq_PE, which is the frequency of PE class. From looking at the rows that contained NA for that column, we realized that the NAs all occurred when a student didn't have PE at school. So, we recorded the missing value to 0. Finally, we had rows that had a weight, and contained information about one's age and gender. So, we decided to use imputation to fill in these missing values. What we did was that if a row had NA, we would pick another row of equal age and gender, and would use all of the values from that row. The reason we decided to do this is because we believe that many of our variables are correlated so it would not make sense to impute each column individually, thus we imputed the entire row. In the end, we went with using random hot deck imputation to take care of our NA values. 